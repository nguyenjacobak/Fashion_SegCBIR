from openai import OpenAI

class open_ai_model:
    def __init__(self, api_key: str, model: str = "gpt-4o-mini", base_url: str = "https://api.openai.com/v1"):
        """
        Khá»Ÿi táº¡o client káº¿t ná»‘i Ä‘áº¿n OpenAI API.
        :param api_key: MÃ£ khÃ³a API (sk-xxxxxx)
        :param base_url: URL base cá»§a API (cÃ³ thá»ƒ thay Ä‘á»•i náº¿u dÃ¹ng proxy hoáº·c Azure)
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model

    # ğŸ’¬ CHAT COMPLETION
    def chat(self, messages: list) -> str:
        """
        Gá»­i há»™i thoáº¡i Ä‘áº¿n mÃ´ hÃ¬nh Chat GPT.
        :param messages: Danh sÃ¡ch tin nháº¯n [{role, content}]
        :return: Ná»™i dung tráº£ lá»i cá»§a mÃ´ hÃ¬nh
        """
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages
        )
        return response.choices[0].message.content

    # ğŸ–¼ï¸ IMAGE GENERATION
    def generate_image(self, prompt: str, model: str = "gpt-image-1") -> str:
        """
        Sinh áº£nh tá»« mÃ´ táº£ vÄƒn báº£n.
        :param prompt: MÃ´ táº£ áº£nh
        :param model: Model táº¡o áº£nh (gpt-image-1)
        :return: URL áº£nh káº¿t quáº£
        """
        image = self.client.images.generate(
            model=model,
            prompt=prompt
        )
        return image.data[0].url

    # ğŸ”Š TEXT TO SPEECH
    def text_to_speech(self, text: str, output_path: str = "output.mp3",
                       model: str = "gpt-4o-mini-tts", voice: str = "alloy"):
        """
        Chuyá»ƒn vÄƒn báº£n thÃ nh giá»ng nÃ³i.
        :param text: VÄƒn báº£n cáº§n chuyá»ƒn
        :param output_path: ÄÆ°á»ng dáº«n file Ã¢m thanh
        :param model: Model TTS
        :param voice: Giá»ng nÃ³i ('alloy', 'verse', 'nova'â€¦)
        """
        with self.client.audio.speech.with_streaming_response.create(
            model=model,
            voice=voice,
            input=text
        ) as response:
            response.stream_to_file(output_path)
        print(f"âœ… File Ã¢m thanh Ä‘Ã£ lÆ°u táº¡i: {output_path}")

    # ğŸ™ï¸ SPEECH TO TEXT
    def speech_to_text(self, file_path: str,
                       model: str = "gpt-4o-mini-transcribe") -> str:
        """
        Nháº­n dáº¡ng giá»ng nÃ³i tá»« file Ã¢m thanh.
        :param file_path: ÄÆ°á»ng dáº«n file Ã¢m thanh
        :param model: Model STT
        :return: VÄƒn báº£n nháº­n dáº¡ng Ä‘Æ°á»£c
        """
        with open(file_path, "rb") as audio_file:
            transcription = self.client.audio.transcriptions.create(
                model=model,
                file=audio_file
            )
        return transcription.text
